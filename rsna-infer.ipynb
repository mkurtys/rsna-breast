{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import partial\n",
    "import os\n",
    "\n",
    "from mkrsna.rsna.loaders.loaders import RSNAData\n",
    "from mkrsna.rsna.model import RSNAModel\n",
    "from mkrsna.torch.collate import mixed_collate_imgs_fn_with_pad_value\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, Normalize,\n",
    "    ImageOnlyTransform\n",
    ")\n",
    "from albumentations.pytorch import ToTensorV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    IS_KAGGLE = True\n",
    "except ImportError:\n",
    "    IS_KAGGLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please download the dataset manually from kaggle\n",
    "DATASET_URI = \"kaggle/rsna-breast-cancer-detection\"\n",
    "DATASET_PATH_SUFFIX = \"\"\n",
    "DATASET_DIR = os.path.split(DATASET_URI)[1]\n",
    "DATASETS_LOCAL_REPO = \"/kaggle/input/\" if IS_KAGGLE else os.path.expanduser(\"~/rsna-breast\")\n",
    "DATASET_PATH_START = os.path.join(DATASETS_LOCAL_REPO, DATASET_DIR)\n",
    "DATASET_PATH = os.path.join(DATASET_PATH_START, DATASET_PATH_SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    checkpoint_path = \"checkpoints/ckpt_epoch05_trainf065.ckpt\"\n",
    "    test_imgs_path = f\"{DATASET_PATH}/test_images\"\n",
    "    test_csv_path = f\"{DATASET_PATH}/test.csv\"\n",
    "    test_bs = 8\n",
    "    dataloader_workers_count = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "str(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_collate_imgs_fn = partial(mixed_collate_imgs_fn_with_pad_value, pad_value=0)\n",
    "\n",
    "class ExpandTo3Channels(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=True, p=1.0):\n",
    "        super().__init__(always_apply=always_apply, p=p)\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        return img.reshape(img.shape[0],img.shape[1],1)*np.ones(3).reshape(1,1,3)\n",
    "\n",
    "    def get_transform_init_args_names(self):\n",
    "        return () \n",
    "\n",
    "valid_augments = Compose([\n",
    "    Normalize(mean=(0.5), std=(0.5), max_pixel_value=1.0, p=1.0),\n",
    "    ExpandTo3Channels(p=1.0),\n",
    "    ToTensorV2(p=1.0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(Config.test_csv_path)\n",
    "test_df['img_name'] = test_df['patient_id'].astype(str) + \"/\" + test_df['image_id'].astype(str) + \".png\"\n",
    "\n",
    "test_dataset = RSNAData(\n",
    "    df = test_df,\n",
    "    img_folder = Config.test_imgs_path,\n",
    "    has_patient_folder_sturcture = True,\n",
    "    resize_longer_axis_to=1024,\n",
    "    pre_resize_for_countours_aspect=0.1,\n",
    "    extension=\"dcm\",\n",
    "    is_test=True,\n",
    "    transform = valid_augments\n",
    ")\n",
    "\n",
    "test_loader = DataLoader( \n",
    "    test_dataset,\n",
    "    batch_size=Config.test_bs,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=mixed_collate_imgs_fn,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_model = RSNAModel.load_from_checkpoint(checkpoint_path = Config.checkpoint_path, pretrained=False)\n",
    "scripted_model = eval_model.to_torchscript()\n",
    "scripted_model = eval_model.to(device)\n",
    "scripted_model.eval()\n",
    "scripted_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkurtys/projects/rsna-breast/mkrsna/rsna/loaders/loaders.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  img = torch.tensor(img, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = []\n",
    "indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_imgs, batch_indices in test_loader:\n",
    "        cancer_predictions = scripted_model.predict(batch_imgs.to(device))\n",
    "        predictions.extend(cancer_predictions.cpu().detach().numpy().flatten().tolist())\n",
    "        indices.extend(batch_indices.cpu().detach().numpy().tolist())\n",
    "\n",
    "summary_df = pd.DataFrame({\"prediction_id\": test_df[\"prediction_id\"].values[indices], \"cancer\": predictions})\n",
    "submission_series = summary_df.groupby([\"prediction_id\"])[\"cancer\"].max()\n",
    "submission_series.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "162031026a4efa8d84847d4df476c8bd36ac5090b05403e52aeffa53b6cd40e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
