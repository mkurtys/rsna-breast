{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:56:39.619623Z","iopub.status.busy":"2023-01-18T10:56:39.619094Z","iopub.status.idle":"2023-01-18T10:56:39.641979Z","shell.execute_reply":"2023-01-18T10:56:39.640611Z","shell.execute_reply.started":"2023-01-18T10:56:39.619518Z"},"trusted":true},"outputs":[],"source":["# Convert DICOMS from RSNA challange to 16 bit PNGS"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-05T12:20:58.392314Z","iopub.status.busy":"2023-02-05T12:20:58.391667Z","iopub.status.idle":"2023-02-05T12:20:58.412396Z","shell.execute_reply":"2023-02-05T12:20:58.411650Z","shell.execute_reply.started":"2023-02-05T12:20:58.392281Z"},"trusted":true},"outputs":[{"data":{"text/plain":["4"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import multiprocessing\n","\n","multiprocessing.cpu_count()"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:56:39.644673Z","iopub.status.busy":"2023-01-18T10:56:39.644314Z","iopub.status.idle":"2023-01-18T10:56:39.655554Z","shell.execute_reply":"2023-01-18T10:56:39.654057Z","shell.execute_reply.started":"2023-01-18T10:56:39.644642Z"},"trusted":true},"outputs":[],"source":["# pre_resize_dims = None\n","resize_dim = 1024+512\n","# apply_voi_lut = False\n","limit_files = None\n","files_border_percent=None # 0.5\n","files_border_process_lower=False,\n","\n","# None to get cpucount\n","jobs_count = None\n","\n","# Constants\n","U16MAX = 65535"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:56:39.657553Z","iopub.status.busy":"2023-01-18T10:56:39.657215Z","iopub.status.idle":"2023-01-18T10:56:39.669234Z","shell.execute_reply":"2023-01-18T10:56:39.668199Z","shell.execute_reply.started":"2023-01-18T10:56:39.657524Z"},"trusted":true},"outputs":[],"source":["import os\n","from pathlib import Path\n","try:\n","    from kaggle_secrets import UserSecretsClient\n","    IS_KAGGLE = True\n","except ImportError:\n","    IS_KAGGLE = False"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:56:39.671929Z","iopub.status.busy":"2023-01-18T10:56:39.671582Z","iopub.status.idle":"2023-01-18T10:56:39.684435Z","shell.execute_reply":"2023-01-18T10:56:39.682787Z","shell.execute_reply.started":"2023-01-18T10:56:39.671899Z"},"trusted":true},"outputs":[],"source":["# if not IS_KAGGLE:\n","#    !pip install --upgrade kaggle\n","#    !mkdir ~/.kaggle\n","#    !mv kaggle.json ~/.kaggle/kaggle.json\n","#    !kaggle competitions download -c rsna-breast-cancer-detection\n","#    !unzip -q rsna-breast-cancer-detection.zip -d rsna-breast-cancer-detection\n","    "]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:56:39.686604Z","iopub.status.busy":"2023-01-18T10:56:39.686260Z","iopub.status.idle":"2023-01-18T10:56:39.696019Z","shell.execute_reply":"2023-01-18T10:56:39.695158Z","shell.execute_reply.started":"2023-01-18T10:56:39.686574Z"},"trusted":true},"outputs":[],"source":["competition_path = Path('~/rsna-breast/rsna-breast-cancer-detection').expanduser()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:56:39.697907Z","iopub.status.busy":"2023-01-18T10:56:39.697417Z","iopub.status.idle":"2023-01-18T10:58:19.218400Z","shell.execute_reply":"2023-01-18T10:58:19.216969Z","shell.execute_reply.started":"2023-01-18T10:56:39.697876Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (1.24.1)\n","Collecting numpy\n","  Downloading numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (1.5.3)\n","Requirement already satisfied: pydicom in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (2.3.1)\n","Collecting dicomsdl\n","  Downloading dicomsdl-0.109.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (4.64.1)\n","Requirement already satisfied: opencv-python in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (4.7.0.72)\n","Collecting pylibjpeg\n","  Downloading pylibjpeg-1.4.0-py3-none-any.whl (28 kB)\n","Collecting pylibjpeg-openjpeg\n","  Downloading pylibjpeg_openjpeg-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting pylibjpeg-libjpeg\n","  Downloading pylibjpeg_libjpeg-1.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting python-gdcm\n","  Downloading python_gdcm-3.0.21-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting pycocotools\n","  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from pandas) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from pandas) (2.8.2)\n","Requirement already satisfied: matplotlib>=2.1.0 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from pycocotools) (3.6.3)\n","Requirement already satisfied: pyparsing>=2.2.1 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.38.0)\n","Requirement already satisfied: pillow>=6.2.0 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (9.4.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.0.7)\n","Requirement already satisfied: packaging>=20.0 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (23.0)\n","Requirement already satisfied: six>=1.5 in /home/mkurtys/.pyenv/versions/3.10.9/envs/torch/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Building wheels for collected packages: pycocotools\n","  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl size=390977 sha256=aedbe7756bd67d32fb35d19b7bedfbc78c0717915a1396d62eb42b2d0afedddc\n","  Stored in directory: /home/mkurtys/.cache/pip/wheels/89/5c/59/e3cd7600cf164a071163f9fed6550a29185d64345591f7d9fe\n","Successfully built pycocotools\n","Installing collected packages: python-gdcm, numpy, dicomsdl, pylibjpeg-openjpeg, pylibjpeg-libjpeg, pylibjpeg, pycocotools\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.24.1\n","    Uninstalling numpy-1.24.1:\n","      Successfully uninstalled numpy-1.24.1\n","Successfully installed dicomsdl-0.109.1 numpy-1.24.2 pycocotools-2.0.6 pylibjpeg-1.4.0 pylibjpeg-libjpeg-1.3.4 pylibjpeg-openjpeg-1.3.2 python-gdcm-3.0.21\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["if IS_KAGGLE:\n","    # !pip uninstall numpy\n","    !pip install --upgrade --force numpy pandas pydicom dicomsdl tqdm opencv-python pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg python-gdcm pycocotools\n","else:\n","    !pip install --upgrade numpy pandas pydicom dicomsdl tqdm opencv-python pylibjpeg pylibjpeg-openjpeg pylibjpeg-libjpeg python-gdcm pycocotools"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:58:19.223502Z","iopub.status.busy":"2023-01-18T10:58:19.222958Z","iopub.status.idle":"2023-01-18T10:58:20.210758Z","shell.execute_reply":"2023-01-18T10:58:20.209625Z","shell.execute_reply.started":"2023-01-18T10:58:19.223446Z"},"trusted":true},"outputs":[],"source":["import glob\n","import cv2\n","import functools\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","import pydicom\n","import pydicom.pixel_data_handlers\n","import numpy as np\n","import cv2\n","import os\n","from joblib import Parallel, delayed\n","from tqdm.notebook import tqdm\n","from pathlib import Path\n","import random\n","import multiprocessing as mp\n","import itertools\n","from typing import Optional, Iterable\n","import seaborn as sns\n","import pandas as pd\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:58:20.212894Z","iopub.status.busy":"2023-01-18T10:58:20.212559Z","iopub.status.idle":"2023-01-18T10:58:20.220162Z","shell.execute_reply":"2023-01-18T10:58:20.219208Z","shell.execute_reply.started":"2023-01-18T10:58:20.212863Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using jobs  3\n"]}],"source":["if jobs_count is None:\n","    print(f\"Using jobs  { mp.cpu_count()-1}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:58:20.222734Z","iopub.status.busy":"2023-01-18T10:58:20.221524Z","iopub.status.idle":"2023-01-18T10:58:20.234072Z","shell.execute_reply":"2023-01-18T10:58:20.232738Z","shell.execute_reply.started":"2023-01-18T10:58:20.222696Z"},"trusted":true},"outputs":[],"source":["def image_resize(image, width = None, height = None, inter = cv2.INTER_LINEAR):\n","    dim = None\n","    (h, w) = image.shape[:2]\n","\n","    if width is None and height is None:\n","        return image\n","\n","    if width is None:\n","        r = height / float(h)\n","        dim = (int(w * r), height)\n","    else:\n","        r = width / float(w)\n","        dim = (width, int(h * r))\n","    resized = cv2.resize(image, dim, interpolation = inter)\n","\n","    return resized\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:58:20.236435Z","iopub.status.busy":"2023-01-18T10:58:20.235999Z","iopub.status.idle":"2023-01-18T10:58:20.250270Z","shell.execute_reply":"2023-01-18T10:58:20.249276Z","shell.execute_reply.started":"2023-01-18T10:58:20.236399Z"},"trusted":true},"outputs":[],"source":[" \n","\n","\n","def normalization_with_min_max(img, val_min, val_max):\n","    if val_min<val_max:\n","        return (img - val_min)/(val_max - val_min)\n","    else:\n","        return img\n","\n","def normalization(img):\n","    val_min = np.amin(img)\n","    val_max = np.amax(img)\n","    return normalization_with_min_max(img, val_min, val_max), val_min, val_max\n","    \n","\n","def truncation_normalization(img, val_min, val_max):\n","    truncated = np.clip(img,val_min, val_max)\n","    normalized = (truncated - val_min)/(val_max - val_min)\n","    return normalized"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T10:58:20.253002Z","iopub.status.busy":"2023-01-18T10:58:20.251961Z","iopub.status.idle":"2023-01-18T10:58:20.271485Z","shell.execute_reply":"2023-01-18T10:58:20.270563Z","shell.execute_reply.started":"2023-01-18T10:58:20.252963Z"},"trusted":true},"outputs":[],"source":["\n","def find_contours(img, \n","                  threshold_level: int):\n","    blured = cv2.GaussianBlur(img, (7, 7), 0)\n","    \n","    thresholded = np.zeros_like(blured, dtype=np.uint8)\n","    thresholded[ blured >= threshold_level ] = 1\n","    \n","    cnts, _ = cv2.findContours(thresholded,\n","                               cv2.RETR_EXTERNAL,\n","                               cv2.CHAIN_APPROX_SIMPLE)\n","    # print(f\" contours len {len(cnts)}\")\n","    \n","    return cnts\n","\n","def largest_countour_and_coords_or_image_size(cnts, img):\n","    if cnts:\n","        cnt = max(cnts, key = cv2.contourArea)\n","        x, y, w, h = cv2.boundingRect(cnt)\n","        return cnt, (x,y,w,h)\n","    else:\n","        return None, (0, 0, img.shape[1], img.shape[0])\n","\n","\n","\n","#  'WindowCenter',\n","#  'WindowWidth',\n","#  'RescaleIntercept',\n","#  'RescaleSlope',\n","#  'RescaleType',\n","#  'VOILUTFunction',\n","\n","def data_to_monochrome2_if_needed(data, ds):     \n","    if ds.PhotometricInterpretation == \"MONOCHROME1\":\n","        data_max = np.amax(data)\n","        return data_max - data  \n","    else:\n","        return data\n","\n","def img_crop(img, threshold_level):\n","    contours = find_contours(img, threshold_level=threshold_level)\n","    #cv.drawContours(\timage, contours, contourIdx, color[, thickness[, lineType[, hierarchy[, maxLevel[, offset]]]]]\t) -> \timage\n","    max_cnt, cnt_coords = largest_countour_and_coords_or_image_size(contours, img)\n","    max_cnt_mask=None\n","    max_cnt_mask = np.zeros_like(img, dtype=np.uint8)\n","    if max_cnt is not None:\n","        cv2.drawContours(max_cnt_mask, [max_cnt], -1 , 1, cv2.FILLED)\n","        croped_img = np.where(max_cnt_mask > 0 , img, max_cnt_mask)\n","        # img = cv2.bitwise_or(img, img, mask=max_cnt_mask)\n","        x,y,w,h = cnt_coords\n","        croped_img = croped_img[y:y+h, x:x+w]\n","    else:\n","        croped_img = img.copy()\n","        \n","    return croped_img, cnt_coords, max_cnt_mask \n","\n","def process(filename):\n","    ds = pydicom.dcmread(filename)\n","    data = ds.pixel_array\n","    voi_data = pydicom.pixel_data_handlers.apply_voi_lut(data, ds)\n","    # data = data_to_monochrome2_if_needed(data, ds)\n","    voi_data = data_to_monochrome2_if_needed(voi_data, ds)\n","    img_croped, crop_coords, _ = img_crop(voi_data, threshold_level=5)\n","    \n","    img_croped, _, _ = normalization(img_croped)\n","    img_croped = img_croped*U16MAX\n","    img_croped=img_croped.astype(np.uint16)\n","    return data, img_croped, crop_coords\n","\n","def process_and_save(filename, output_dir, resize_longer_axis_to=None):\n","    original_img, img_croped, crop_coords = process(filename)\n","    \n","    if resize_longer_axis_to:\n","        img_croped=image_resize(img_croped, height=resize_longer_axis_to)\n","    \n","    png_filename = str(filename.stem + \".png\")\n","    directory = Path(output_dir, *filename.parts[-3:-1])\n","    directory.mkdir(parents=True, exist_ok=True)\n","    path_to_save = directory/png_filename\n","    # print(path_to_save)\n","    cv2.imwrite(str(path_to_save), img_croped)\n","    return (original_img.shape[1], original_img.shape[0]), crop_coords\n","\n","def process_and_save_star(args):\n","    return process_and_save(*args)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T11:00:23.180205Z","iopub.status.busy":"2023-01-18T11:00:23.179221Z","iopub.status.idle":"2023-01-18T11:00:23.196567Z","shell.execute_reply":"2023-01-18T11:00:23.195262Z","shell.execute_reply.started":"2023-01-18T11:00:23.180152Z"},"trusted":true},"outputs":[],"source":["def bulk_process_and_save(input_directory,\n","                          resize_longer_axis_to=512,\n","                          limit_files=None,\n","                          files_border_percent=None,\n","                          files_border_process_lower=True,\n","                          jobs_count=None):\n","    jobs_count = mp.cpu_count()-1 if jobs_count is None else jobs_count\n","\n","    \n","    output_path = Path(\".\")\n","    files = [image_path for directory_path in input_directory.iterdir()\n","             for image_path in directory_path.iterdir()]\n","    \n","    # if resize_dims:\n","    #    for resize_dim in resize_dims:\n","    #        os.makedirs( os.path.join(str(output_path), str(resize_dim)),\n","    #                    exist_ok=True)\n","    \n","    \n","    \n","    if limit_files:\n","        files = files[:limit_files]\n","        \n","    if files_border_percent:\n","        total_files_len = len(files)\n","        border_guess = int(len(files)*files_border_percent)\n","        # continue while all images for patient will be processed\n","        border = border_guess\n","        start_patient_id = files[border].parts[-2]\n","        patient_id = start_patient_id\n","        print(start_patient_id)\n","        while border < len(files) and patient_id==start_patient_id:\n","            border+=1\n","            patient_id = files[border].parts[-2]\n","            \n","            \n","        if files_border_process_lower:\n","            files = files[:border]\n","        else:\n","            files = files[border:]\n","        print(f\"out of {total_files_len}, the {len(files)} will be processed\")\n","        \n","    \n","    os.makedirs(str(output_path), exist_ok=True)\n","    # opencv use threads, it may be somewhat faster, but may not\n","    \n","    if jobs_count>0:\n","        with mp.Pool(jobs_count) as p:\n","            t = tqdm(p.imap(process_and_save_star,\n","                                  zip(files, \n","                                      itertools.repeat(output_path),\n","                                      itertools.repeat(resize_longer_axis_to))),\n","                     total=len(files))\n","            dims =  list(t)\n","    else:\n","        dims = []\n","        for file in tqdm(files):\n","            d=process_and_save(file, output_path, resize_longer_axis_to)\n","            dims.append(d)\n","    dims_df = pd.DataFrame.from_records(dims, columns=[\"size\", \"crop\"])\n","    dims_df[\"filepath\"] = files\n","    return dims_df\n","            \n","    "]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T11:00:30.831908Z","iopub.status.busy":"2023-01-18T11:00:30.831477Z","iopub.status.idle":"2023-01-18T12:03:46.569753Z","shell.execute_reply":"2023-01-18T12:03:46.567448Z","shell.execute_reply.started":"2023-01-18T11:00:30.831876Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"677257a54d7e4a6994d15a1bbee7e1ab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/54706 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["crop_df= bulk_process_and_save(competition_path/\"train_images\",\n","                               resize_longer_axis_to=resize_dim,\n","                               limit_files=limit_files,\n","                               files_border_percent=files_border_percent,\n","                               files_border_process_lower=files_border_process_lower,\n","                               jobs_count=jobs_count)\n","crop_df.to_csv(\"crop_train.csv\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.status.busy":"2023-01-18T11:00:20.925544Z","iopub.status.idle":"2023-01-18T11:00:20.925993Z","shell.execute_reply":"2023-01-18T11:00:20.925810Z","shell.execute_reply.started":"2023-01-18T11:00:20.925790Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ca97aa6222f64cb8a6555933e7df1b43","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["crop_df= bulk_process_and_save(competition_path/\"test_images\",\n","                               resize_longer_axis_to=resize_dim,\n","                               limit_files=None,\n","                               files_border_percent=None,\n","                               jobs_count=jobs_count)\n","crop_df.to_csv(\"crop_test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2023-01-18T11:00:20.927697Z","iopub.status.idle":"2023-01-18T11:00:20.928155Z","shell.execute_reply":"2023-01-18T11:00:20.927944Z","shell.execute_reply.started":"2023-01-18T11:00:20.927924Z"},"trusted":true},"outputs":[],"source":["# copy test train\n","!cp {competition_path}/test.csv .\n","!cp {competition_path}/train.csv ."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"torch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"vscode":{"interpreter":{"hash":"162031026a4efa8d84847d4df476c8bd36ac5090b05403e52aeffa53b6cd40e5"}}},"nbformat":4,"nbformat_minor":4}
